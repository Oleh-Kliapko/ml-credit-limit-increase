# ML Models: Прогнозування підвищення кредитного ліміту

## Опис проекту

Проект аналізує дані клієнтів для прогнозування ймовірності підвищення кредитного ліміту протягом 30 днів після оцінки.

**Бізнес-завдання**
Визначити клієнтів, яким з високою ймовірністю підвищать ліміт, щоб оптимізувати кредитну політику та зменшити ризики.

**Дані**
Кредитна історія, поведінка, демографія тощо.
Формат файлу має бути - feather-файл (`data/dataset.feather`).

**Таргет**
Бінарний клас: підвищення ліміту на ≥ 5000 грн (абсолютний приріст).
Дисбаланс: ~2.61 % позитивного класу.

## Основні етапи пайплайну

1. Завантаження даних
2. Оптимізація типів даних (зменшення обсягу пам'яті)
3. Аудит категоріальних ознак
4. Аналіз лімітів (pre vs in30d)
5. Формування таргету
6. Видалення leakage-колонок
7. Аналіз та обробка пропусків
8. Кореляційний аналіз з таргетом
9. Інженерія ознак → 10 фінальних фіч
10. Тренування вибраної моделі (або кількох)
11. Розрахунок метрик (AUC, Gini, Precision, Recall, F1, F2)
12. Пошук оптимального порогу за F2
13. Precision при фіксованому Recall = 0.8
14. Збереження моделі, графіків ROC/PR, порівняльної таблиці

## Структура проекту

DATA SCIENCE/
└── ML_models/
├── models/ # Конфігурації моделей (легко додавати нові)
│ ├── logreg.py
│ ├── xgboost.py
│ ├── lightgbm.py
│ └── histgb.py
├── metrics/ # допоміжні функції для метрик
│ ├── threshold_optimization.py
│ └── precision_at_fixed_recall.py
├── reports/ # Результати: моделі (.pkl), графіки, порівняння
├── data/ # Вхідний датасет (dataset.feather)
├── config.py # Шляхи до даних
├── load_data.py # Завантаження .feather
├── optimize_numerical.py # Оптимізація пам'яті (з int64/float64 → менші типи)
├── audit_categorical.py # Аудит категоріальних ознак
├── limit_stats.py # Статистика лімітів
├── create_target.py # Формування таргету
├── drop_leakage.py # Видалення leakage-колонок
├── missing_analysis.py # Аналіз пропусків
├── handle_missing_values.py# Обробка пропусків
├── correlation_analysis.py # Кореляція з таргетом
├── feature_engineering.py # Інженерія ознак (виділено 10 фінальних фіч)
├── validate_columns.py # Перевірка наявності потрібних колонок
├── model_selector.py # Інтерактивний вибір моделі користувачем
├── train_model_base.py # Універсальне тренування, метрики, графіки, збереження
├── metrics_report.py # Звіт по метриках з інтерпретацією
├── model_comparison.py # Порівняльна таблиця моделей (CSV + PNG)
├── main.py

## Як запустити

1. Створіть загальну папку `DATA SCIENCE`
2. Скопіюйте папку з проектом `ML_models`
3. Додайте в папку відповідний датасет `dataset.feather`
4. Перейдіть у загальну папку `cd "/Users/.../..../DATA SCIENCE`
5. Активуйте віртуальне середовище `source ML_models/.venv/bin/activate`
6. Встановіть необхідні пакети ``
7. Запустіть пайплайн `python -m ML_models.main`
8. Спочатку програма оптимізує датасет для побудови моделей.
9. Після чого оберіть модель:
   - `logreg`
   - `xgboost`
   - `lightgbm`
   - `histgb`
     або `all` щоб тренувати всі (рекомендовано)

## Результати

Після виконання в папці `ML_models/reports/` з'являться:

1. {model_name}.pkl — збережені моделі
2. {model_name}\_baseline_curves.png — графіки ROC та Precision-Recall
3. model_comparison.csv — порівняльна таблиця
4. model_comparison.png — візуальна таблиця

## Використані технології

- Python 3.14
- pandas, numpy, scikit-learn, logging, importlib, matplotlib, joblib
- XGBoost, LightGBM
